# E-Portfolio

---

## Introducing Myself And My Abilities
---
# **Describing Myself**
### My name is Constandinos Kyriacou. 
### I describe myself as an inquisitive and ambitious mathematician and statistician. 
### Furthermore, I look forward to divulging myself into a world of knowledge , involving data science and into the broader computing world, as I am currently seeking to complete my graduate degree in data science.
###  Lastly, I look forward to securing a position as a data scientist in the current market.


---
# **Education**

## Undegraduate degree at **University of Cyprus**
## Mathematics and Statistics, Sep 2017 - Jun 2021 
### Grade: 6,70
### Activities and societies: Research studies and additional seminars regarding the field of Mathematics, Statistics and Data Handling.
### Additional Information: I was able to partake in seminars that deepened my knowledge of data visualisation and modelling.
![uo_cyprus_logo](https://user-images.githubusercontent.com/101480754/159297620-87b33331-f1ed-4099-ad8d-8700c218212f.jpeg)


---
## Graduate degree in process at **University of Essex Online**
## Field of **Data Science**
![uni of essex online](https://user-images.githubusercontent.com/101480754/159297588-ba088cdb-0290-4c75-8bdb-ae58b851c998.jpeg)


---
# **Soft Skills**
#### Problem Solving (Expert)
#### Critical Thinking (Expert)
#### Creative Thinking (Expert)
#### Interpersonal Skills (Advanced)
#### Analytical Thinking (Intermediate)

---
# **Hard Skills**
### Advanced Knowledge of Applied Statistics
### Advanced Knowledge of Pure Mathematics
### Intermediate Knowledge of Computational Mathematics
### Intermediate Knowledge of Numerical Analysis
### Intermediate Knowledge Regarding Data Handling and Data Modelling

---
# **Programming Languages**
### Intermediate Knowledge of the HTML programming language.
### Intermediate Knowledge of the MATLAB programming language
### Intermediate Knowledge of the R programming language 
---
# Projects and Endeavours


## Unit 1 (Introduction to Big Data Technologies and Data Management):
#### Discussion Topic: Critically evaluate the rationale behind the Internet of Things (IOT), in the context of the article by Huxley et al (2020), highlighting the opportunities, limitations, risks and challenges associated with such a large-scale process of data collection.
![1](https://user-images.githubusercontent.com/101480754/207056200-851cccf8-4eb0-4911-b729-c07a2adf5979.jpg)

![2](https://user-images.githubusercontent.com/101480754/207056288-fb4bf6d4-1a0a-4932-87aa-69ae7fa80f47.jpg)

 




#### Comments: This was the first individual work that enabled us to point out the opportunities, limitations, risks and challenges in relation with the data collection process. After anally examining the Lecturecast and other literature, most relevant to the topic, I managed to contribute to the discussion as follows. Following the completion of this task, I received an immense amount of information regarding the data collection process (opportunities, limitations, risks and challenges) which will present to be a very significant skill for my career afterwards, as a data scientist in which I will have to be capable of retrieving, handling large quantities of data and managing to take the correct data-driven decisions.


## Unit 2 (Introduction to Data Types and Formats):
#### Assignment: Considering what you have now learned in Units 1 and 2, you should respond to at least three of your peers' contributions from the Collaborative Discussion 1. To guide you, look at the guidelines for the peer review process on the Department's page (Group/Teamwork).




![1](https://user-images.githubusercontent.com/101480754/207115317-d6840b89-b46a-43cf-9de5-f5a997868824.jpg)
![2](https://user-images.githubusercontent.com/101480754/207115336-ee6c6c43-bf7f-4a34-a4ce-b7cb1aff3164.jpg)





#### Comments: In exploring the obligations of my master’s degree, I was called to process information provided by my peers and submit specific notes as to promote their improvement in terms of the accuracy of their written work. Additionally, in relation to the promotion of the accuracy of their work, I inherently as a response to an assignment, formulated specific questions in order to promote the retrieval of missed information produced in their written work.This specific occurrence served as the first time I attempted to interact with my peers in a written manner with previously formulated content. It is important to mention that these individuals were chosen to be my teammates in a group project in the Units 6 and 11 within the module.  Within the aforementioned process, I read the essays of my fellow peers, and after careful consideration of their work, I formulated replies in a manner that promoted the expression of my own thoughts as for the adjustment of their content for their improvement of their written content, whilst also inherently producing questions as to allow for the clarification of certain aspects unexplored within their work. 



## Unit 3 (Data Collection and Storage):
#### Assignment: In this third and final week of your first discussion, you should provide a summary post based on your initial post, the feedback from your peers and the content of Units 1, 2 and 3. Please label this as ‘Summary Post’. It should be 300 words



![1](https://user-images.githubusercontent.com/101480754/207075539-4cd05e6b-31e6-4707-81f2-95652db494de.jpg)


![2](https://user-images.githubusercontent.com/101480754/207075605-bb0c984d-c415-4e7c-b267-cda7ecf63bf6.jpg)






#### Comments: Within the implications of enacting in unit 3, I was called to gather information from both units, one and two, as to provide a summary post in regards to the posting of my initial post in unit 1 the feedback from my peers in unit 2 and lastly the implementation of the content provided in the previous and current units.The objective of the specific assignment contributed to a well-rounded understanding of the matter at hand and as such gave me the material necessary to relay information about this topic.


## Unit 4 (Completion of the Data Management Pipeline Test):


<img width="1321" alt="Screenshot 2022-12-12 at 4 26 09 PM" src="https://user-images.githubusercontent.com/101480754/207070398-95677a71-21a3-4141-bbeb-6e3a2604f95e.png">




 




#### Comments: This specific unit obligated my person to complete the data management pipeline test, which was automatically marked with its completion.This test enabled us to notice certain weaknesses in the knowledge obtained by the collective student unit, with regards to individual testing in the Data Management Pipeline. A Data Management Pipeline is a way of transporting data from one place (the source) to a destination (such as a data warehouse). During this procedure, the data is transformed and optimized so that it can be used to draw subsequent conclusions. More specifically the Data Management Pipeline consists of the following steps: 
##### 1)Capturing raw data (The extraction of data from primary sources where data is kept or used)
##### 2)Data cleaning (Checking data source, parsing, removing of duplicated and redundancies, data scraping, capture header information to enable logical and semantically relevant processing of data )
##### 3)Data integration (Is the process of gathering data from different sources and fit them together)
##### 4)Database design (It is the procedure of designing data models using a database management system)
##### 5)Data analysis (The process of analyzing the data to reach to obtain the correct conclusions)
##### 6)Data Visualization( It is the procedure of representing data in a graphical form which is more understandable by the user)



## Unit 5 (Data Cleaning and Automating Data Collections):
#### Comments: The implications of in acting with the materials given in unit 5, have been conditioned to be the practical application of data cleaning, allocating python examples in accordance with data taken from household-level surveys carried out by UNICEF.As per enacting within the 5th unit, it becomes apparent that the subject at hand is the practice of data cleaning. Data cleaning can be defined as the process by which we formulate our data in a dataset in such a way that we fix or remove each data that is incorrect, incomplete, remove duplicates and filter unwanted outliers as well. Additionally, this procedure ensures that the dataset contains only accurate information. Therefore, this unit aided my person in expanding my knowledge in data cleaning and comprehend how I can practically implement the data cleaning techniques using Python examples.



## Unit 6 (Database Design and Normalisation):
#### Instructions Concerning the Project: For the first part of your assessment, you are advised to position yourself and your team as IT Software Consultants and Developers. You have been commissioned to design and build a single logical database. You get to choose the application environment (and hence the client profile), and it is recommended that you choose an area of interest in a work environment or public service. This could be the postal service, retail industry/customer service, transport system, security services or the floral industry.

#### Once you have confirmed your design, you are required to develop the database and present an executive summary to the senior management team, describing how it meets their requirements.

#### Your team is expected to prepare and deliver a design report of your intended development work for the organisation. Please refer to the Lecturecast in this unit for guidance. Your design should capture the following. Please Note: The associated grading criteria are highlighted in the requirements below, to be reviewed alongside the Grading Criteria (in Module Resources).

#### Logical design - data items/entities, attributes of the data items chosen, relationships and associations. Identify and explain the data types used and data formats selected.
#### Critically evaluate the data management pipeline process with regards to discussing the capturing of the data used and detailing its source, documenting how you implemented data cleaning techniques and the stages that have been carried out during the cleaning process.
#### Produce a proposal of the database build, creating an intended database model design. You should propose a database management system that you will be using for the build, taking into account the requirements of storage, user access, and the manipulation and retrieval of data within the proposed database.
#### Presentation and Structure of your work (weighted at 25%) includes spelling, style, evidence of proofreading, correct use (and format) of citations and references.
#### Appendices should not be used to extend the core report as reports should stand alone, complete and concise, without the appendices. They should really only be used if required, and only for supplementary and/ or supporting information. One key part of the exercises in this module is the need to be to be able to express ideas succinctly, concisely and with necessary brevity.




![1](https://user-images.githubusercontent.com/101480754/207074963-4406fc49-845a-4f87-a2ad-0f217d8e7a87.jpg)

![2](https://user-images.githubusercontent.com/101480754/207074985-049da056-1742-4c36-ad2d-0650031c8ee4.jpg)

![3](https://user-images.githubusercontent.com/101480754/207074994-2e350a76-0b16-491f-8faa-291ae6ab48f1.jpg)

![4](https://user-images.githubusercontent.com/101480754/207075010-79bbc632-6cb8-4bfc-812c-4302e9cc115c.jpg)

#### Comments: In this unit my person had the opportunity to be allocated in a unit regarding the project, allowing for my person to cooperate with Panagiotis and Tsitsi as to achieve the execution of this project. The project topic was to design and build a single logical database in an area of our preference. My responsibility was the first part of the project in which I manage to create the logical design of the database (data items/entities, attributes of the data items chosen, relationships and associations).Apart from the knowledge gained regarding the project’s subject, the entity of my team was able to develop skills such as cooperation, communication, and organization. These values are regarded as the epitome of a well-trained and professional individual within the workplace, as such it is applicable to mention that these skills aid an individual to achieve success within a unit in the workplace.

### Feedback:


![2 feedback](https://user-images.githubusercontent.com/101480754/207076053-fa718268-d2ed-407b-8d78-6c839de08ba8.jpg)








## Unit 7 (Constructing Normalised Tables and Database Build):


![me](https://user-images.githubusercontent.com/101480754/207074343-44966a5d-6747-45c2-8524-fff75823c89a.jpg)




![0](https://user-images.githubusercontent.com/101480754/207073926-4ee9f523-c3bf-44e9-a59e-2520c558d653.jpg)

 


![3](https://user-images.githubusercontent.com/101480754/207074147-127a0ed9-a85c-475c-b827-4f31e76fac09.jpg)


![4](https://user-images.githubusercontent.com/101480754/207074234-92d69ca8-ad4c-4ccd-b164-33989ff63e6e.jpg)







#### Comments: In this unit we focused on constructing normalized tables and database build. More specifically, my person was given a table in un-normalized form, and after following specific steps which are shown in detail in the document, I managed to comply the table with the 3rd Normal Form (3 NF). In continuance with the completion of the first part of the task, I was able to proceed to the next process allocated within a series of procedures I needed to complete. This step was allocated to build a relational database system, with linked tables, enacting in the application of primary and foreign keys.This unit was imperative to my person gaining knowledge on certain procedures regarding normalized tables and database build. The integration of certain rules applying to the creation of normalized tables can be allocated below. This procedure is intendent to prevent anomalies(unexpected errors of the data ),as such insertion anomalies, deletion anomalies and modification anomalies. Additionally, it must be noted that the differentiation of both keys lies within the differentiation of their function. Primary key is one or more columns which offer uniqueness for every individual record in a table while a foreign key is a column in a table which refers to a column in a different table ensuring referential integrity.

#### Specifically,a table which applies in 1st Normal Form (1 NF),2nd Normal Form (2 NF) and 3rd Normal Form(3 NF)  should follow the specific objectives respectively :

#### First Normal Form(1 NF):
##### -All rows must be unique (no duplicate rows)
##### -Each cell must only contain a single value (not a list)
##### -Each value should be non dividible(can’t be split out further)

#### Second Normal Form (2 NF):
##### -Follow the First Normal Form (1 NF) and 
##### -All attributes (non-key columns) dependent on the key (no partial-dependency)

#### Third Normal Form (3 NF):
##### -Follow the Second Normal Form (2 NF) and 
##### -Remove transitive dependencies between non-primary key columns.







## Unit 8 (Compliance and Regulatory Framework for Managing Data):
### Collaborative Discussion 2 - Comparing Compliance Laws:
#### Assignment: Compare the rules of the GDPR - in particular, with relation to the securing of personal data rule, with either similar compliance laws within your country of residence, or with the ICO in the UK.

#### The ICO refers to this rule as 'Security' and you should discuss your findings in relation to the standards set out and the exemptions that exist:

#### 'The securing personal data principle of the GDPR: Personal data shall be processed in a manner that ensures appropriate security of the personal data...' (ICO.org.uk).

![unit 8](https://user-images.githubusercontent.com/101480754/207063335-c35e3ae7-3c0a-4a42-887a-4b15d510f864.jpg)

#### Comments: The collaborative discussion allocated in Unit 8 required of the individuals in attendance of the module to compare the rules of EU GDPR vs UK GDPR. The implications of enacting within the exercises provided in unit 8 allowed for the learning of new knowledge. Generally, in enacting within the material given within this unit my person was able to understand specific regulations regarding data and it's use in certain areas. Generally, the GDPR are legal regulations in relation to the data protection and privacy, so their application is crucial for each organization which handles data. Therefore, as a future data scientist who will work on a daily basis with data, the detailed knowledge of the principles is necessary.




## Unit 9 (Database Management Systems (DBMS) and Models): 
### Seminar Preparation:
#### Most Python codes and datasets are provided in files included in the Kazil textbook’s repository (see Unit 2 and 4 Reading). The main aim here is therefore not learning the Python programming language, but rather learning how Python may be used in data analysis.

#### Complete an example with storing data in a relational database. The example uses SQLite and includes the following parts:

#### Installing SQLite and setting a relational database with Python: See the section Setting Up Your Local Database with Python on pages 145-146 of the Kazil textbook. You are also able to use the SQL workspace in Codio.
#### Saving the cleaned UNICEF dataset into the SQLite database: See pages 193-194 and refer to Unit 4 if necessary.

#### In relation to the new knowledge obtained, the Unit 9 was mainly conjured to involve the Database Management Systems (DBMS) and study of data models. The DBMS are software systems which are used as a connection between an end-user and a database. Therefore, DBMS give us the opportunity to interact with databases, including creating, reading, updating and deleting data in the database). In addition to this, database models, is the way the database is implemented. They are divided into three categories:
##### -Hierarchical model (simpler relationship, easy to handle).
##### -The network approach (more flexible, difficult to develop due to its complexity of the relationships among entities)
##### -The relational model (the most usual data model, useful for connecting related tables and viewing the data from different angles). Subsequently, during the Unit 9 seminar preparation my person moved on to the more practical side of this topic, which is allocated as building a DBMS. In fact, I managed to install SQLite, which is defined as a programming language which is used for extracting data from a database. In turn, I produced a relational database. This database is based on the relational model of data adhering to Python programming. Lastly, I saved the cleaned UNICEF dataset into the SQLite database.






https://user-images.githubusercontent.com/101480754/208127987-07e6cfeb-d98b-4978-b5fe-1608fe7862b1.mp4




https://user-images.githubusercontent.com/101480754/208128021-20b83aa9-9a45-41d2-8e09-5cce2d3bc922.mp4





https://user-images.githubusercontent.com/101480754/208128054-d6a277d5-9f13-4af0-876a-53c66ffe1613.mp4





https://user-images.githubusercontent.com/101480754/208128082-1fe8f207-1cbb-42d8-b26b-29dd639f8313.mp4






https://user-images.githubusercontent.com/101480754/208128160-f8675624-d0f7-43cc-abe7-7d9f62e3b42c.mp4









## Unit 10 (More on APIs (Application Programming Interfaces) for Data Parsing):
### API Security Requirements:
##### Assignment: As a team, evaluate the security requirements of an API of your choice and write a brief security requirements specification which mitigates against any risks associated with the API for enabling data sharing, scraping and connectivity between a program code written in Python and any of the following file formats/management systems (XML, JSON and SQL).



![unit10](https://user-images.githubusercontent.com/101480754/207065712-0ef17a16-0da7-4dee-a70b-962330d3a4d7.jpg)

#### Comments: In this unit we focused on Application Programming Interfaces (APIs). Essentially, API stands as the mediator of which two programs interconnect with each other. More specifically, as to define the acronyms standing within the name, it becomes apparent that the acronym of application refers to any software with a particular function and in contrast to this the acronym interface can be considered as the connecting link between two applications. Lastly it is important to mention the acronym for the word programming alluding to the necessity of coding within this interactive system. Therefore, APIs are crucial in the normal function of applications, as they obtain data shared amongst other applications and execute predefined processes as to serve towards efficiency in both time and effort for the creator and for better calibration of many applications.The final part of executing the unit’s objectives was the execution of an assignment of which I was required to assess the security requirements of an API of my preference.  Firstly, becoming acquainted with the security requirements and then following this action, providing certain precautionary measures to limit the risk of API as a way for data sharing, scraping and connectivity.



## Unit 11 (DBMS Transaction and Recovery):
#### Assignment: The second part of the assessment is an Executive Summary of the completed design and build of a logical database based on the project report your team submitted at the end of Unit 6. Ensure you take account of the feedback you have received for the Unit 6 submission.

#### You are required to produce an Executive Summary that pulls together your findings, recommendations and conclusions in a clear and unambiguous format. Your report should also review concepts underlying database modelling and critically evaluate the strengths and weaknesses of the relevant data models used in your design and build. Your recommendations should take into account the legal and compliance requirements applicable to the organisation.

#### You will be submitting a report that informs your client of the outcomes of your analysis and evaluation of your choice of data model highlighting strengths and limitations.






![1](https://user-images.githubusercontent.com/101480754/207077465-2694f8e3-13a2-4b91-a8d9-49d5d7c5deaa.jpg)

![2](https://user-images.githubusercontent.com/101480754/207077490-17cae965-e406-48d6-9c10-fb44e7f24fe5.jpg)

![3](https://user-images.githubusercontent.com/101480754/207077505-5a8e9338-3b29-4884-8f28-fa77905ac176.jpg)



#### Comments: In Unit 11 we were required to submit an assessment. This assessment was produced, as per the finalization part of the collective assessment performed in unit 6.  As per this task, we were required to complete an executive summary regarding the specific topic of the assignment within unit 6. The executive summary included our findings, recommendations, conclusions, list of pros and cons of the relevant data models used in the submission in Unit 6. My person was responsible for the part of the assignment which had to evaluate the strengths and weaknesses of the relevant data models used in our design and build in Unit 6, and the creation of the renewed Entity-Relationship-Diagram based on our recommendations.The outcome of the second part of the project, which was allocated as the executive summary mentioned above, was much better in terms of cooperation, since I was more familiarized with my teammates. We were able to operate as a team in a greater ease due to the familiarity between us and we were also able to conduct tasks with greater organization. The feeling of cooperation and supportiveness was increased and as a result we encouraged each other to produce a better outcome and perform better on the tasks at hand. These facts, in combination with the consideration of the feedback produced by the authoritative figure minding our progress in Unit 6, allowed for the production of greater efficiency within the team. In addition to this, I had the opportunity to notice the importance of values such as communication, cooperation and organization and better instill them in my life as to support my everyday objectives in both a professional and personal level.






## Reflections Regarding The Module:
###   In remembrance of the process I faced during my personal enactment within the obligations of this module, I can recount mostly positive experiences and knowledge earned. This occurred as per my personal enactment within group assignments and individual exercises that procured my personal development and improvement of my skills.
###    More specifically, during the module, we were able to enhance our knowledge in regard to the different data extraction, exploration, cleaning, and modelling techniques, which undoubtedly is of crucial importance as a future data scientist. Furthermore, in relevance to this, a more general objective maintained regarding this topic, was obtaining a general idea on this topic. In regards to this, the collective student unit had the opportunity to get familiarized with the Data Management Pipeline procedure. As to better define this procedure, it is the process of transporting data from one original location (the source) to a destination (such as a data warehouse). During this process, the data is transformed and optimized so that it can be used to draw subsequent conclusions. Adherently there are steps that belong to this procedure, which can be allocated as the capturing of raw data, data cleaning, data integration, database design, data analysis and data visualization.
###    As previously mentioned, during the module we had the opportunity to enhance our skills in regards with the data cleaning procedure. Data cleaning can be defined as the process, by which we formulate our data in a dataset in such a way that we fix or remove each data that is incorrect, incomplete, remove duplicates and filter unwanted outliers as well. Therefore, it ensures that the dataset contains only accurate information. In addition to this, we had the opportunity to become familiarized with the Database Management Systems (DBMS) and study of data models. The DBMS are software systems which are used as a connection between an end-user and a database. Therefore, DBMS grants us with the ability to interact with databases, including creating, reading, updating, and deleting data in the database. In contrast, database model, is the way the database is implemented, and they are divided into three distinct categories which are mentioned to be Hierarchical model, the network approach and the relational model which is the most common of the three data models stated previously. As such, it is adherent to say that a data scientist with a great understanding of knowledge adherent to his field must adapt to handling data and using this information and tools as he sees fit.
###     In relevance to activities being procreated by team efforts, there were many objectives referring to this effort. In accordance with this notion, the use of cooperation, adherence to the opinions of others after debate and the application of a verified answer on all parties allowed for the team to progress in a joint and agreed progression. In addition to this, amongst the many objectives appointed to my team during the enactment of our persons in this module, the necessity for participation in group projects and assignments was prevalent as to produce a better outcome and for the prevalence of the group’s effort. In adjacence to this, due to the familiarization of the team members amongst each other, an environment was set as for the better progression of joint efforts such as projects whilst also adhering to each person's better abilities, as to provide the adequate roles to each party as perceived amongst these noted abilities. This notion, adhering to the greater outcome of the project due to the use of individuals towards their area of expertise as to better set the prerequisites for a perfect scenario including time efficiency, greater cooperation, and organization. 
###   As per the objectives that my team was obligated to complete, I can confirm that my personal enactment was vital to the completion of these previously mentioned objectives. Specifically speaking, my enactment, for the production of the project my team was responsible of producing, was of newfound experience for my person. The objective presented to our team was the creation of a database system in accordance with a transportation system that was acting in real time, as such on par with my individual efforts an additional team effort, entailed the application of logical ideas produced by my team members and myself, to reenact interactions of everyday users and project possible improvements for the application of better terms of use for certain items.
###    In regard to the objectives performed within my involvement in assignments regarded towards individual and group enactment, I feel like I was able to achieve personal growth. As such I can inherently perceive my better understanding of certain practices involving the better cooperation between teammates and additionally, I can further understand the magnitude of development procured within my person as a return for my implications in the aforementioned processes and procedures. More specifically I can notice that certain values have been ingrained in my person especially towards my enactment with others in a team setting, such as cooperation and respect for the opinion of others. As well as these values I have also noticed that my individual adopted certain traits. These traits can be defined as becoming a better listener enabling my person to adhere to certain objectives allowing for others to involve themselves within a creative process that I am also involved. More specifically, a catalyst for my progressive change as an individual can be determined to be the objectives placed within this module and as such can be attributed more specifically to team projects. 
###   Lastly, I desire to describe the overall experience during the module as successful, since I have successfully captured the main objectives of the module and developed a greater understanding towards the sector of data science.

### References:
#### 1)	Admin (no date) Data extraction techniques and Tools, Rosoka. Rosoka Software. Available at: https://www.rosoka.com/blog/data-extraction-techniques#:~:text=In%20terms%20of%20Extraction%20Methods,Full%20Extraction%20and%20Incremental%20Extraction.&text=All%20data%20is%20extracted%20directly%20from%20the%20source%20system%20at%20once. (Accessed: December 12, 2022). 
#### 2)	Guide to data cleaning: Definition, benefits, components, and how to clean your data (no date) Tableau. Available at: https://www.tableau.com/learn/articles/what-is-data-cleaning (Accessed: December 12, 2022). 
#### 3)	Simplilearn (2022) What is data modelling? overview, basic concepts, and types in detail, Simplilearn.com. Simplilearn. Available at: https://www.simplilearn.com/what-is-data-modeling-article#:~:text=The%20following%20are%20the%20types,relationship%2C%20dimensional%2C%20and%20graph. (Accessed: December 12, 2022). 
#### 4)	What is a Data Pipeline & How Does It Work? (2022) Dremio. Available at:https://www.dremio.com/resources/guides/data-pipeline/ (Accessed: December 12, 2022). 




## Contact Information and Additional Accounts

- [Linkedin](https://www.linkedin.com/in/constantinos-kyriacou-datasciencemathstatistics/)
- [Work Email](konstandinoskyriakou@gmail.com)
- [Github](https://github.com/CKyriacou1)


---




---
<p style="font-size:11px">
<!-- Remove above link if you don't want to attibute -->
